{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":958397,"sourceType":"datasetVersion","datasetId":521710},{"sourceId":5117542,"sourceType":"datasetVersion","datasetId":2972192}],"dockerImageVersionId":30407,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input\nfrom keras.optimizers import SGD, Adam, Adadelta, Adagrad\nfrom keras import backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport cv2\nfrom math import log10,sqrt","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:22:16.067812Z","iopub.execute_input":"2023-04-14T18:22:16.068418Z","iopub.status.idle":"2023-04-14T18:22:26.956062Z","shell.execute_reply.started":"2023-04-14T18:22:16.068358Z","shell.execute_reply":"2023-04-14T18:22:26.954705Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data=sorted(os.listdir('/kaggle/input/chest-xrays-radiopaedia/images/images'))\nnoise_data=sorted(os.listdir('/kaggle/input/chest-noisy/chest noisy-20230306T183108Z-001/chest noisy'))","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:22:26.958955Z","iopub.execute_input":"2023-04-14T18:22:26.959767Z","iopub.status.idle":"2023-04-14T18:22:27.886682Z","shell.execute_reply.started":"2023-04-14T18:22:26.959722Z","shell.execute_reply":"2023-04-14T18:22:27.885400Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_dir='/kaggle/input/chest-xrays-radiopaedia/images/images'\nnoise_data_dir='/kaggle/input/chest-noisy/chest noisy-20230306T183108Z-001/chest noisy'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-14T18:22:27.889251Z","iopub.execute_input":"2023-04-14T18:22:27.890209Z","iopub.status.idle":"2023-04-14T18:22:27.896140Z","shell.execute_reply.started":"2023-04-14T18:22:27.890151Z","shell.execute_reply":"2023-04-14T18:22:27.894789Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ntrain_image = []\nfor file in tqdm(sorted(os.listdir(train_data_dir))):\n  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n    image = tf.keras.preprocessing.image.load_img(train_data_dir + '/' + file, target_size=(256,256),color_mode='grayscale')\n    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n    train_image.append(image)\n\ntrain_image = np.array(train_image)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:22:27.897996Z","iopub.execute_input":"2023-04-14T18:22:27.899870Z","iopub.status.idle":"2023-04-14T18:23:58.288608Z","shell.execute_reply.started":"2023-04-14T18:22:27.899821Z","shell.execute_reply":"2023-04-14T18:23:58.287175Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_img(dataset):\n  f,ax=plt.subplots(1,5)\n  f.set_size_inches(40,20)\n  for i in range(5,10):\n    ax[i-5].imshow(dataset[i], cmap='gray')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:23:58.291634Z","iopub.execute_input":"2023-04-14T18:23:58.292038Z","iopub.status.idle":"2023-04-14T18:23:58.298785Z","shell.execute_reply.started":"2023-04-14T18:23:58.291999Z","shell.execute_reply":"2023-04-14T18:23:58.297445Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"noised_image = []\nfor file in tqdm(sorted(os.listdir(noise_data_dir))):\n  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n    image = tf.keras.preprocessing.image.load_img(noise_data_dir + '/' + file, target_size=(256,256),color_mode='grayscale')\n    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n    noised_image.append(image)\n\nnoised_image = np.array(noised_image)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:23:58.299858Z","iopub.execute_input":"2023-04-14T18:23:58.300315Z","iopub.status.idle":"2023-04-14T18:26:11.257867Z","shell.execute_reply.started":"2023-04-14T18:23:58.300274Z","shell.execute_reply":"2023-04-14T18:26:11.256471Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_image.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:11.259623Z","iopub.execute_input":"2023-04-14T18:26:11.260002Z","iopub.status.idle":"2023-04-14T18:26:11.267332Z","shell.execute_reply.started":"2023-04-14T18:26:11.259964Z","shell.execute_reply":"2023-04-14T18:26:11.265999Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_img(train_image)\n# import matplotlib.pyplot as plt\n#plt.imshow(train_image)\n#plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:11.269339Z","iopub.execute_input":"2023-04-14T18:26:11.270161Z","iopub.status.idle":"2023-04-14T18:26:12.607622Z","shell.execute_reply.started":"2023-04-14T18:26:11.270106Z","shell.execute_reply":"2023-04-14T18:26:12.606625Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_img(noised_image)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:12.609234Z","iopub.execute_input":"2023-04-14T18:26:12.609866Z","iopub.status.idle":"2023-04-14T18:26:14.239982Z","shell.execute_reply.started":"2023-04-14T18:26:12.609828Z","shell.execute_reply":"2023-04-14T18:26:14.238193Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xnoised=noised_image[:400]\nxtest=noised_image[400:]","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:14.241719Z","iopub.execute_input":"2023-04-14T18:26:14.242832Z","iopub.status.idle":"2023-04-14T18:26:14.248360Z","shell.execute_reply.started":"2023-04-14T18:26:14.242777Z","shell.execute_reply":"2023-04-14T18:26:14.246998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\n\ndef autoencoder():\n    # Input layer\n    inputs = Input(shape=(256, 256, 1))\n\n    # Encoder\n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n\n    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n\n    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n\n    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n\n    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n\n    # Decoder\n    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n    merge6 = concatenate([up6, conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n    merge7 = concatenate([up7, conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n    merge8 = concatenate([up8, conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n    \n    up9 = Conv2DTranspose(64, (2, 2), strides=(2,2), padding='same')(conv8)\n    merge9 = concatenate([up9, conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n    \n    # Output layer\n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n# Compile the model\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:14.250029Z","iopub.execute_input":"2023-04-14T18:26:14.250640Z","iopub.status.idle":"2023-04-14T18:26:14.275330Z","shell.execute_reply.started":"2023-04-14T18:26:14.250593Z","shell.execute_reply":"2023-04-14T18:26:14.273642Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model= autoencoder()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:14.276952Z","iopub.execute_input":"2023-04-14T18:26:14.277637Z","iopub.status.idle":"2023-04-14T18:26:15.094120Z","shell.execute_reply.started":"2023-04-14T18:26:14.277590Z","shell.execute_reply":"2023-04-14T18:26:15.092562Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nmodel = autoencoder()\nmodel.compile(optimizer='adam', loss='mse')\nplot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:15.095578Z","iopub.execute_input":"2023-04-14T18:26:15.095931Z","iopub.status.idle":"2023-04-14T18:26:16.141823Z","shell.execute_reply.started":"2023-04-14T18:26:15.095896Z","shell.execute_reply":"2023-04-14T18:26:16.140312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with tf.device('/device:GPU:0'):\n    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n    model.fit(xnoised, xnoised, epochs= 2, batch_size=1, validation_data=(xtest, xtest), callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-04-14T18:26:16.147276Z","iopub.execute_input":"2023-04-14T18:26:16.147763Z","iopub.status.idle":"2023-04-14T20:55:00.088631Z","shell.execute_reply.started":"2023-04-14T18:26:16.147714Z","shell.execute_reply":"2023-04-14T20:55:00.086838Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xtrain= train_image[100:]","metadata":{"execution":{"iopub.status.busy":"2023-04-14T20:55:00.090727Z","iopub.execute_input":"2023-04-14T20:55:00.091184Z","iopub.status.idle":"2023-04-14T20:55:00.097486Z","shell.execute_reply.started":"2023-04-14T20:55:00.091134Z","shell.execute_reply":"2023-04-14T20:55:00.096065Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred= model.predict(xtest[:10])\ndef plot_predictions(y_true, y_pred):    \n    f, ax = plt.subplots(4, 5)\n    f.set_size_inches(10.5,7.5)\n    for i in range(10):\n        ax[0][i].imshow(np.reshape(xtrain[i], (256,256,1)), aspect='auto', cmap='gray')\n        ax[1][i].imshow(np.reshape(y_true[i], (256,256,1)), aspect='auto', cmap='gray')\n        ax[2][i].imshow(np.reshape(y_pred[i], (256,256,1)), aspect='auto', cmap='gray')\n        ax[3][i].imshow(cv2.medianBlur(xtrain[i], (5)), aspect='auto', cmap='gray')\n    plt.tight_layout()\nplot_predictions(xtest[:10], pred[:10])","metadata":{"execution":{"iopub.status.busy":"2023-04-14T20:55:00.099690Z","iopub.execute_input":"2023-04-14T20:55:00.100546Z","iopub.status.idle":"2023-04-14T20:55:13.470672Z","shell.execute_reply.started":"2023-04-14T20:55:00.100498Z","shell.execute_reply":"2023-04-14T20:55:13.468405Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"median_blur = cv2.medianBlur(xtrain[0], (5))\ngaussian_blur=cv2.GaussianBlur(xtrain[0],(5,5),0)\naverage_blur=cv2.blur(xtrain[0],(5,5))\nbilateral_filter=cv2.bilateralFilter(xtrain[0],9,75,75)\nf,ax=plt.subplots(1,5)\nf.set_size_inches(40,20)\nax[0].imshow(pred[0].reshape(256,256,1), cmap='gray')\nax[0].set_title('Autoencoder Image')\nax[1].imshow(median_blur,cmap='gray')\nax[1].set_title('Median Filter')\nax[2].imshow(gaussian_blur,cmap='gray')\nax[2].set_title('Gaussian Filter')\nax[3].imshow(average_blur,cmap='gray')\nax[3].set_title('Average Filter')\nax[4].imshow(bilateral_filter,cmap='gray')\nax[4].set_title('Bilateral Filter')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T21:20:15.123265Z","iopub.execute_input":"2023-04-14T21:20:15.125048Z","iopub.status.idle":"2023-04-14T21:20:16.905292Z","shell.execute_reply.started":"2023-04-14T21:20:15.124963Z","shell.execute_reply":"2023-04-14T21:20:16.903239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def PSNR(original, denoised): \n    mse = np.mean((original - denoised) ** 2) \n    if(mse == 0): \n        return 100\n    max_pixel = 255.0\n    psnr = 20 * log10(max_pixel / sqrt(mse)) \n    return psnr \n\n  \n#value1 = PSNR(xtest[0], median_blur)\nvalue2 = PSNR(xtrain[0], pred[0])\n#value3 = PSNR(xtest[0], gaussian_blur)\n#value4 = PSNR(xtest[0], average_blur)\n#value5 = PSNR(xtest[0], bilateral_filter)\n#value6 = PSNR(xtrain[0],pred[0])\n\nprint(\"PSNR values\")\nprint(f\"Autoencoder Image : {value2} dB\")\n#print(f\"Median Filter Image : {value1} dB\")\n#print(f\"Gaussian Filter Image : {value3} dB\")\n#print(f\"Average Filter Image : {value4} dB\")\n#print(f\"Bilateral Filter Image : {value5} dB\")\n#print(f\"Noisy Image : {value6} dB\")","metadata":{"execution":{"iopub.status.busy":"2023-04-14T21:20:45.681451Z","iopub.execute_input":"2023-04-14T21:20:45.681890Z","iopub.status.idle":"2023-04-14T21:20:45.692639Z","shell.execute_reply.started":"2023-04-14T21:20:45.681852Z","shell.execute_reply":"2023-04-14T21:20:45.691022Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pip install --upgrade scikit-imag","metadata":{"execution":{"iopub.status.busy":"2023-04-14T21:30:42.372485Z","iopub.execute_input":"2023-04-14T21:30:42.372943Z","iopub.status.idle":"2023-04-14T21:30:42.383270Z","shell.execute_reply.started":"2023-04-14T21:30:42.372903Z","shell.execute_reply":"2023-04-14T21:30:42.381774Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from skimage import io, metrics\n\n# # Load the original and processed images\n# img_orig = io.imread(xtest[0])\n# img_proc = io.imread(pred[0])\n# # \n# # Calculate the MSE and PSNR\n# mse = metrics.mean_squared_error(img_orig, img_proc)\n# psnr = metrics.peak_signal_noise_ratio(img_orig, img_proc)\n\n# # Calculate the SSIM\n# ssim = metrics.structural_similarity(img_orig, img_proc, multichannel=True)\n\n# # Print the results\n# print('MSE:',mse)\n# print('PSNR:',psnr)\n# print('SSIM:',ssim)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T20:55:13.482278Z","iopub.status.idle":"2023-04-14T20:55:13.483617Z","shell.execute_reply.started":"2023-04-14T20:55:13.483252Z","shell.execute_reply":"2023-04-14T20:55:13.483290Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pip install --upgrade scikit-image\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T20:55:13.485538Z","iopub.status.idle":"2023-04-14T20:55:13.486213Z","shell.execute_reply.started":"2023-04-14T20:55:13.485856Z","shell.execute_reply":"2023-04-14T20:55:13.485891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}